<!DOCTYPE html>
<<html lang="en" data-qb-installed="true"><head><style>
    @property --tw-border-style {
syntax: '*';
inherits: false;
initial-value: solid;
}
@property --tw-font-weight {
syntax: '*';
inherits: false;
}
@property --tw-shadow {
syntax: '*';
inherits: false;
initial-value: 0 0 #0000;
}
@property --tw-shadow-color {
syntax: '*';
inherits: false;
}
@property --tw-inset-shadow {
syntax: '*';
inherits: false;
initial-value: 0 0 #0000;
}
@property --tw-inset-shadow-color {
syntax: '*';
inherits: false;
}
@property --tw-ring-color {
syntax: '*';
inherits: false;
}
@property --tw-ring-shadow {
syntax: '*';
inherits: false;
initial-value: 0 0 #0000;
}
@property --tw-inset-ring-color {
syntax: '*';
inherits: false;
}
@property --tw-inset-ring-shadow {
syntax: '*';
inherits: false;
initial-value: 0 0 #0000;
}
@property --tw-ring-inset {
syntax: '*';
inherits: false;
}
@property --tw-ring-offset-width {
syntax: '<length>';
inherits: false;
initial-value: 0px;
}
@property --tw-ring-offset-color {
syntax: '*';
inherits: false;
initial-value: #fff;
}
@property --tw-ring-offset-shadow {
syntax: '*';
inherits: false;
initial-value: 0 0 #0000;
}
@property --tw-ease {
syntax: '*';
inherits: false;
}
@property --tw-content {
syntax: '*';
initial-value: '';
inherits: false;
}
@property --tw-outline-style {
syntax: '*';
inherits: false;
initial-value: solid;
}

</style>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Anushka Gupta</title>

<link rel="stylesheet" type="text/css" href="stylesheet.css">
<link href="css/bootstrap.min.css" rel="stylesheet" media="screen">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>
<script src="js/scramble.js"></script>

<meta name="author" content="Anushka Gupta">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="Description" content="Anushka Gupta (fliptrail) | Chairperson Of IEEEBBDU Student Branch | BTech Computer Science-Artificial Intelligence at BBDU Lucknow '26">
<meta name="keywords" content="Anushka Gupta, fliptrail, Computer Science Engineering - Artificial Intelligence, Machine Learning Model, Data Science Engineer, Deep Learning, Project Management, BBDU Lucknow, Data Analysis, CHAIRPERSON IEEE BBDU Student Branch">

<link rel="icon" type="image/png" href="">

<!-- Replace Google Analytics tag with your own if you are cloning this template -->
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-8EQTMHM42K"></script>

<style id="NotiflixNotifyInternalCSS">[id^=NotiflixNotifyWrap]{pointer-events:none;position:fixed;z-index:4001;opacity:1;right:10px;top:10px;width:280px;max-width:96%;-webkit-box-sizing:border-box;box-sizing:border-box;background:transparent}[id^=NotiflixNotifyWrap].nx-flex-center-center{max-height:calc(100vh - 20px);overflow-x:hidden;overflow-y:auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-orient:vertical;-webkit-box-direction:normal;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-box-align:center;-webkit-align-items:center;-ms-flex-align:center;align-items:center;margin:auto}[id^=NotiflixNotifyWrap]::-webkit-scrollbar{width:0;height:0}[id^=NotiflixNotifyWrap]::-webkit-scrollbar-thumb{background:transparent}[id^=NotiflixNotifyWrap]::-webkit-scrollbar-track{background:transparent}[id^=NotiflixNotifyWrap] *{-webkit-box-sizing:border-box;box-sizing:border-box}[id^=NotiflixNotifyOverlay]{-webkit-transition:background .3s ease-in-out;-o-transition:background .3s ease-in-out;transition:background .3s ease-in-out}[id^=NotiflixNotifyWrap]>div{pointer-events:all;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;font-family:"Quicksand",-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,sans-serif;width:100%;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-align:center;-webkit-align-items:center;-ms-flex-align:center;align-items:center;position:relative;margin:0 0 10px;border-radius:5px;background:#1e1e1e;color:#fff;padding:10px 12px;font-size:14px;line-height:1.4}[id^=NotiflixNotifyWrap]>div:last-child{margin:0}[id^=NotiflixNotifyWrap]>div.nx-with-callback{cursor:pointer}[id^=NotiflixNotifyWrap]>div.nx-with-icon{padding:8px;min-height:56px}[id^=NotiflixNotifyWrap]>div.nx-paused{cursor:auto}[id^=NotiflixNotifyWrap]>div.nx-notify-click-to-close{cursor:pointer}[id^=NotiflixNotifyWrap]>div.nx-with-close-button{padding:10px 36px 10px 12px}[id^=NotiflixNotifyWrap]>div.nx-with-icon.nx-with-close-button{padding:6px 36px 6px 6px}[id^=NotiflixNotifyWrap]>div>span.nx-message{cursor:inherit;font-weight:normal;font-family:inherit!important;word-break:break-all;word-break:break-word}[id^=NotiflixNotifyWrap]>div>span.nx-close-button{cursor:pointer;-webkit-transition:all .2s ease-in-out;-o-transition:all .2s ease-in-out;transition:all .2s ease-in-out;position:absolute;right:8px;top:0;bottom:0;margin:auto;color:inherit;width:20px;height:20px}[id^=NotiflixNotifyWrap]>div>span.nx-close-button:hover{-webkit-transform:rotate(90deg);transform:rotate(90deg)}[id^=NotiflixNotifyWrap]>div>span.nx-close-button>svg{position:absolute;width:16px;height:16px;right:2px;top:2px}[id^=NotiflixNotifyWrap]>div>.nx-message-icon{position:absolute;width:40px;height:40px;font-size:30px;line-height:40px;text-align:center;left:8px;top:0;bottom:0;margin:auto;border-radius:inherit}[id^=NotiflixNotifyWrap]>div>.nx-message-icon-fa.nx-message-icon-fa-shadow{color:inherit;background:rgba(0,0,0,.15);-webkit-box-shadow:inset 0 0 34px rgba(0,0,0,.2);box-shadow:inset 0 0 34px rgba(0,0,0,.2);text-shadow:0 0 10px rgba(0,0,0,.3)}[id^=NotiflixNotifyWrap]>div>span.nx-with-icon{position:relative;float:left;width:calc(100% - 40px);margin:0 0 0 40px;padding:0 0 0 10px;-webkit-box-sizing:border-box;box-sizing:border-box}[id^=NotiflixNotifyWrap]>div.nx-rtl-on>.nx-message-icon{left:auto;right:8px}[id^=NotiflixNotifyWrap]>div.nx-rtl-on>span.nx-with-icon{padding:0 10px 0 0;margin:0 40px 0 0}[id^=NotiflixNotifyWrap]>div.nx-rtl-on>span.nx-close-button{right:auto;left:8px}[id^=NotiflixNotifyWrap]>div.nx-with-icon.nx-with-close-button.nx-rtl-on{padding:6px 6px 6px 36px}[id^=NotiflixNotifyWrap]>div.nx-with-close-button.nx-rtl-on{padding:10px 12px 10px 36px}[id^=NotiflixNotifyOverlay].nx-with-animation,[id^=NotiflixNotifyWrap]>div.nx-with-animation.nx-fade{-webkit-animation:notify-animation-fade .3s ease-in-out 0s normal;animation:notify-animation-fade .3s ease-in-out 0s normal}@-webkit-keyframes notify-animation-fade{0%{opacity:0}100%{opacity:1}}@keyframes notify-animation-fade{0%{opacity:0}100%{opacity:1}}[id^=NotiflixNotifyWrap]>div.nx-with-animation.nx-zoom{-webkit-animation:notify-animation-zoom .3s ease-in-out 0s normal;animation:notify-animation-zoom .3s ease-in-out 0s normal}@-webkit-keyframes notify-animation-zoom{0%{-webkit-transform:scale(0);transform:scale(0)}50%{-webkit-transform:scale(1.05);transform:scale(1.05)}100%{-webkit-transform:scale(1);transform:scale(1)}}@keyframes notify-animation-zoom{0%{-webkit-transform:scale(0);transform:scale(0)}50%{-webkit-transform:scale(1.05);transform:scale(1.05)}100%{-webkit-transform:scale(1);transform:scale(1)}}[id^=NotiflixNotifyWrap]>div.nx-with-animation.nx-from-right{-webkit-animation:notify-animation-from-right .3s ease-in-out 0s normal;animation:notify-animation-from-right .3s ease-in-out 0s normal}@-webkit-keyframes notify-animation-from-right{0%{right:-300px;opacity:0}50%{right:8px;opacity:1}100%{right:0;opacity:1}}@keyframes notify-animation-from-right{0%{right:-300px;opacity:0}50%{right:8px;opacity:1}100%{right:0;opacity:1}}[id^=NotiflixNotifyWrap]>div.nx-with-animation.nx-from-left{-webkit-animation:notify-animation-from-left .3s ease-in-out 0s normal;animation:notify-animation-from-left .3s ease-in-out 0s normal}@-webkit-keyframes notify-animation-from-left{0%{left:-300px;opacity:0}50%{left:8px;opacity:1}100%{left:0;opacity:1}}@keyframes notify-animation-from-left{0%{left:-300px;opacity:0}50%{left:8px;opacity:1}100%{left:0;opacity:1}}[id^=NotiflixNotifyWrap]>div.nx-with-animation.nx-from-top{-webkit-animation:notify-animation-from-top .3s ease-in-out 0s normal;animation:notify-animation-from-top .3s ease-in-out 0s normal}@-webkit-keyframes notify-animation-from-top{0%{top:-50px;opacity:0}50%{top:8px;opacity:1}100%{top:0;opacity:1}}@keyframes notify-animation-from-top{0%{top:-50px;opacity:0}50%{top:8px;opacity:1}100%{top:0;opacity:1}}[id^=NotiflixNotifyWrap]>div.nx-with-animation.nx-from-bottom{-webkit-animation:notify-animation-from-bottom .3s ease-in-out 0s normal;animation:notify-animation-from-bottom .3s ease-in-out 0s normal}@-webkit-keyframes notify-animation-from-bottom{0%{bottom:-50px;opacity:0}50%{bottom:8px;opacity:1}100%{bottom:0;opacity:1}}@keyframes notify-animation-from-bottom{0%{bottom:-50px;opacity:0}50%{bottom:8px;opacity:1}100%{bottom:0;opacity:1}}[id^=NotiflixNotifyOverlay].nx-with-animation.nx-remove,[id^=NotiflixNotifyWrap]>div.nx-with-animation.nx-fade.nx-remove{opacity:0;-webkit-animation:notify-remove-fade .3s ease-in-out 0s normal;animation:notify-remove-fade .3s ease-in-out 0s normal}@-webkit-keyframes notify-remove-fade{0%{opacity:1}100%{opacity:0}}@keyframes notify-remove-fade{0%{opacity:1}100%{opacity:0}}[id^=NotiflixNotifyWrap]>div.nx-with-animation.nx-zoom.nx-remove{-webkit-transform:scale(0);transform:scale(0);-webkit-animation:notify-remove-zoom .3s ease-in-out 0s normal;animation:notify-remove-zoom .3s ease-in-out 0s normal}@-webkit-keyframes notify-remove-zoom{0%{-webkit-transform:scale(1);transform:scale(1)}50%{-webkit-transform:scale(1.05);transform:scale(1.05)}100%{-webkit-transform:scale(0);transform:scale(0)}}@keyframes notify-remove-zoom{0%{-webkit-transform:scale(1);transform:scale(1)}50%{-webkit-transform:scale(1.05);transform:scale(1.05)}100%{-webkit-transform:scale(0);transform:scale(0)}}[id^=NotiflixNotifyWrap]>div.nx-with-animation.nx-from-top.nx-remove{opacity:0;-webkit-animation:notify-remove-to-top .3s ease-in-out 0s normal;animation:notify-remove-to-top .3s ease-in-out 0s normal}@-webkit-keyframes notify-remove-to-top{0%{top:0;opacity:1}50%{top:8px;opacity:1}100%{top:-50px;opacity:0}}@keyframes notify-remove-to-top{0%{top:0;opacity:1}50%{top:8px;opacity:1}100%{top:-50px;opacity:0}}[id^=NotiflixNotifyWrap]>div.nx-with-animation.nx-from-right.nx-remove{opacity:0;-webkit-animation:notify-remove-to-right .3s ease-in-out 0s normal;animation:notify-remove-to-right .3s ease-in-out 0s normal}@-webkit-keyframes notify-remove-to-right{0%{right:0;opacity:1}50%{right:8px;opacity:1}100%{right:-300px;opacity:0}}@keyframes notify-remove-to-right{0%{right:0;opacity:1}50%{right:8px;opacity:1}100%{right:-300px;opacity:0}}[id^=NotiflixNotifyWrap]>div.nx-with-animation.nx-from-bottom.nx-remove{opacity:0;-webkit-animation:notify-remove-to-bottom .3s ease-in-out 0s normal;animation:notify-remove-to-bottom .3s ease-in-out 0s normal}@-webkit-keyframes notify-remove-to-bottom{0%{bottom:0;opacity:1}50%{bottom:8px;opacity:1}100%{bottom:-50px;opacity:0}}@keyframes notify-remove-to-bottom{0%{bottom:0;opacity:1}50%{bottom:8px;opacity:1}100%{bottom:-50px;opacity:0}}[id^=NotiflixNotifyWrap]>div.nx-with-animation.nx-from-left.nx-remove{opacity:0;-webkit-animation:notify-remove-to-left .3s ease-in-out 0s normal;animation:notify-remove-to-left .3s ease-in-out 0s normal}@-webkit-keyframes notify-remove-to-left{0%{left:0;opacity:1}50%{left:8px;opacity:1}100%{left:-300px;opacity:0}}@keyframes notify-remove-to-left{0%{left:0;opacity:1}50%{left:8px;opacity:1}100%{left:-300px;opacity:0}}</style><style type="text/css">.lf-progress {
-webkit-appearance: none;
-moz-apperance: none;
width: 100%;
/* margin: 0 10px; */
height: 4px;
border-radius: 3px;
cursor: pointer;
}
.lf-progress:focus {
outline: none;
border: none;
}
.lf-progress::-moz-range-track {
cursor: pointer;
background: none;
border: none;
outline: none;
}
.lf-progress::-webkit-slider-thumb {
-webkit-appearance: none !important;
height: 13px;
width: 13px;
border: 0;
border-radius: 50%;
background: #0fccce;
cursor: pointer;
}
.lf-progress::-moz-range-thumb {
-moz-appearance: none !important;
height: 13px;
width: 13px;
border: 0;
border-radius: 50%;
background: #0fccce;
cursor: pointer;
}
.lf-progress::-ms-track {
width: 100%;
height: 3px;
cursor: pointer;
background: transparent;
border-color: transparent;
color: transparent;
}
.lf-progress::-ms-fill-lower {
background: #ccc;
border-radius: 3px;
}
.lf-progress::-ms-fill-upper {
background: #ccc;
border-radius: 3px;
}
.lf-progress::-ms-thumb {
border: 0;
height: 15px;
width: 15px;
border-radius: 50%;
background: #0fccce;
cursor: pointer;
}
.lf-progress:focus::-ms-fill-lower {
background: #ccc;
}
.lf-progress:focus::-ms-fill-upper {
background: #ccc;
}
.lf-player-container :focus {
outline: 0;
}
.lf-popover {
position: relative;
}

.lf-popover-content {
display: inline-block;
position: absolute;
opacity: 1;
visibility: visible;
transform: translate(0, -10px);
box-shadow: 0 2px 5px 0 rgba(0, 0, 0, 0.26);
transition: all 0.3s cubic-bezier(0.75, -0.02, 0.2, 0.97);
}

.lf-popover-content.hidden {
opacity: 0;
visibility: hidden;
transform: translate(0, 0px);
}

.lf-player-btn-container {
display: flex;
align-items: center;
}
.lf-player-btn {
cursor: pointer;
fill: #999;
width: 14px;
}

.lf-player-btn.active {
fill: #555;
}

.lf-popover {
position: relative;
}

.lf-popover-content {
display: inline-block;
position: absolute;
background-color: #ffffff;
opacity: 1;

transform: translate(0, -10px);
box-shadow: 0 2px 5px 0 rgba(0, 0, 0, 0.26);
transition: all 0.3s cubic-bezier(0.75, -0.02, 0.2, 0.97);
padding: 10px;
}

.lf-popover-content.hidden {
opacity: 0;
visibility: hidden;
transform: translate(0, 0px);
}

.lf-arrow {
position: absolute;
z-index: -1;
content: '';
bottom: -9px;
border-style: solid;
border-width: 10px 10px 0px 10px;
}

.lf-left-align,
.lf-left-align .lfarrow {
left: 0;
right: unset;
}

.lf-right-align,
.lf-right-align .lf-arrow {
right: 0;
left: unset;
}

.lf-text-input {
border: 1px #ccc solid;
border-radius: 5px;
padding: 3px;
width: 60px;
margin: 0;
}

.lf-color-picker {
display: flex;
flex-direction: row;
justify-content: space-between;
height: 90px;
}

.lf-color-selectors {
display: flex;
flex-direction: column;
justify-content: space-between;
}

.lf-color-component {
display: flex;
flex-direction: row;
font-size: 12px;
align-items: center;
justify-content: center;
}

.lf-color-component strong {
width: 40px;
}

.lf-color-component input[type='range'] {
margin: 0 0 0 10px;
}

.lf-color-component input[type='number'] {
width: 50px;
margin: 0 0 0 10px;
}

.lf-color-preview {
font-size: 12px;
display: flex;
flex-direction: column;
align-items: center;
justify-content: space-between;
padding-left: 5px;
}

.lf-preview {
height: 60px;
width: 60px;
}

.lf-popover-snapshot {
width: 150px;
}
.lf-popover-snapshot h5 {
margin: 5px 0 10px 0;
font-size: 0.75rem;
}
.lf-popover-snapshot a {
display: block;
text-decoration: none;
}
.lf-popover-snapshot a:before {
content: '‚•º';
margin-right: 5px;
}
.lf-popover-snapshot .lf-note {
display: block;
margin-top: 10px;
color: #999;
}
.lf-player-controls > div {
margin-right: 5px;
margin-left: 5px;
}
.lf-player-controls > div:first-child {
margin-left: 0px;
}
.lf-player-controls > div:last-child {
margin-right: 0px;
}
</style></head>
<body class="bg_colour" jf-observer-attached="true">
<table border="0" class="bg_colour" style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
        <td style="padding:0px">
            
            <!-- Name tab -->
            <table border="0" class="bg_colour" style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                
                
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:20%;max-width:20%">
                        <a href="images/pp2.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/pp2.jpg" class="img-circle"></a>
                    </td>
                    <td style="padding:2.5%;width:60%;vertical-align:middle">
                        <div style="text-align:center">
                            <h1><span>Anushka Gupta</span></h1>
                            <small>Click on the email to unscramble.</small><br>
                            
                            <b>Academic Email</b>:
                            <span id="email" style="display:inline;"> <a href="#" style="color: rgb(0,0,0)" onclick="emailScramble.initAnimatedBubbleSort();return false;">anushkag472004@bbdu.ac.in.</a></span>
                            <script>
                                emailScramble = new scrambledString(document.getElementById('email'),
                                    'emailScramble', 'ni.ca.udbb@400274gakhsuna',
                                    [34,33,32,31,30,29, 28, 27,26,25,24,23,22,21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]);
                            </script>
                            <br>
                    
                            <b>Personal Email</b>:
                            <span id="email2" style="display:inline;"> <a href="#" style="color: rgb(0,0,0)" onclick="emailScramble2.initAnimatedBubbleSort();return false;">anushkag472004@gmail.com</a></span>
                            <script>
                                emailScramble2 = new scrambledString(document.getElementById('email2'),
                                    'emailScramble2', 'moc.liamg@400274gakhsuna',
                                    [21,20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]);
                            </script>
                        </div>
                        <p style="text-align:center">
                            <!-- &nbsp;|&nbsp;
                            <a href="#news" onclick="Expand('news')">News</a>
                            &nbsp;|&nbsp;
                            <a href="#education" onclick="Expand('education')">Education</a>
                            &nbsp;|&nbsp;
                            <a href="#experience" onclick="Expand('experience')">Experience</a>
                            &nbsp;|&nbsp;
                            <a href="#publications" onclick="Expand('publications')">Publications</a>
                            &nbsp;|&nbsp;
                            <a href="#projects" onclick="Expand('projects')">Projects</a>
                            &nbsp;|&nbsp;
                            <a href="mailto:hajawaseem4@gmail.com">Contact</a> -->
                            &nbsp;|&nbsp;
                            <a href="https://anushkagupta.github.io/blogs/">Blog</a>
                            &nbsp;|&nbsp;
                        </p>
                    </td>                        
                    <td style="padding:2.5%;width:10%;max-width:10%">

                    </td>
                </tr>

            </tbody></table>
            
            
            <!-- About section, quick links -->

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr style="padding:0px">
                    <td style="padding:2.5%;width:63%;vertical-align:middle">
                        <p>
                            I am a third-year undergraduate student at Babu Banarasi Das University Lucknow where I'm majoring in Computer Science Engineering and Artificial Intelligence with a passion for building impactful tech solutions that solve real-world problems. As the Founder and Chairperson of the first IEEE Society and Computer Society at Babu Banarasi Das University, I blend leadership with innovation to create meaningful change. I am specifically interested in AI Chatbots and Machine Learning models where I am currently focussing on improving robustness, ensuring fairness and preserving user's privacy.
                        </p>
                        <p>
                            I worked under the guidance of <a href="https://scholar.google.co.in/citations?hl=en&amp;user=J-VlCNYAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Sanket Biswas</a> and <a href="https://scholar.google.co.in/citations?hl=en&amp;user=92pWl-AAAAAJ&amp;view_op=list_works&amp;sortby=pubdate">Josep Llados</a> at the <a href="https://www.cvc.uab.es/">Computer Vision Center</a>, focusing on enhancing the capabilities of vision-language models for the task of language-controlled document editing. Our work has been accepted for presentation at the WACV 2025 conference's workshop on Computer Vision Systems for Document Analysis and Recognition.
                        </p>
                        <p>
                            I was a visiting researcher under <a href="https://scholar.google.com/citations?user=2qx0RnEAAAAJ&amp;hl=en">Dr. Karthik Nandakumar</a>  at MBZUAI, Abu Dhabi, where I worked on federated learning for extreme non-iid scenarios.
                        </p>
                        <p>
                            I spent my Summer'2024 as <a href="https://mbzuai.ac.ae/ugrip/">UGRIP intern</a> at MBZUAI, Abu Dhabi, where I worked on analysing the hallucination of LLM's responses to principled prompts under <a href="https://zhiqiangshen.com/">Dr. Zhiqiang Shen</a>. We also collected human and model preferences for each of the response pair for future study on preference based optimization.  
                        </p>
                        <p>
                            Previously, I did a Research Internship under <a href="https://scholar.google.co.in/citations?hl=en&amp;user=oLJTcXIAAAAJ">Dr Ravi Kiran Sarvadevabhatla</a> at <a href="https://cvit.iiit.ac.in/">CVIT</a> Lab in IIIT Hyderabad to generate precise text line segmentation for complex Indic and Southeast Asian historical palm leaf.
                        </p>
                        <!-- <p>I completed my B.Tech. in Computer Science from <a href="https://www.iitp.ac.in" target="_blank">Indian Institute of Technology (IIT) Patna</a>
                            where I spent some excellent four years of my life. My thesis supervised by <a href="https://scholar.google.co.in/citations?user=w2xZ3KYAAAAJ&hl=en" target="_blank">Prof. Jimson Mathew</a> received the Institute Proficiency Prize for Best Bachelor Thesis among students graduating in 2022. 
                            <!-- It highlighted a novel non-monotonic gradient descent optimizer -->
                            <!-- which aims to reduce the number of divergences while using gradient descent, along with its theoretical and empirical validation. 
                        </p>
                        <p>
                            During my bachelors, I interned at <a href="https://mit.edu/" target="_blank">MIT Media Lab</a>, <a href="https://www.sybill.ai/" target="_blank">Sybill.ai</a>, 
                            and was a <a href="https://summerofcode.withgoogle.com/archive/2019/projects/5185272927485952/" target="_blank">Google Summer of Code (GSoC)</a> student.
                        </p>
                         -->
                        <p>
                            Please feel free to check out my <a href="" target="Anushka_Gupta_Resume">resume</a>.
                            You can also find me on other spaces below.
                        </p>
                        <br>
                        <p style="text-align:center">
                            &nbsp;~&nbsp;
                            <a href="https://twitter.com/hwaseem04" target="_blank"> ùïè (Twitter) </a> &nbsp;|&nbsp;
                            <!-- <a href="https://drive.google.com/file/d/1fr6ufcUtGAbgSvX5ICJvp33_EEHiykUq/view" target="_blank" >Resume</a> &nbsp|&nbsp -->
                            <!-- <a href="https://scholar.google.co.in/citations?user=PySXCeAAAAAJ&hl=en" target="_blank" >Google Scholar</a> &nbsp|&nbsp -->
                            <a href="https://github.com/anushkagupta47" target="_blank">Github</a> &nbsp;|&nbsp;
                            <a href="https://linkedin.com/in/anushkagupta47" target="_blank">LinkedIn</a> 
                            &nbsp;~&nbsp;
                        </p>
                    </td>
                </tr>
            </tbody></table>
            <hr class="soft">
<!-- News -->

            <!-- <br> -->
            <button style="border:0px transparent; background-color: transparent;outline:none;" type="button" class="collapsible" data-toggle="collapse" data-target="#content-news" id="news" jf-ext-button-ct="news"><heading>News</heading></button>
            <!-- <div class="container"> -->
            <div id="content-news" class="collapse in">
            <!-- <div class="scroll">  -->

            <table border="0" class="bg_colour" style="padding:10px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                    <td>
                        <p style="color:darkblue; display:inline">Dec '24 &nbsp;</p>
                    </td>
                    <td>
                        Our paper <a href="" target="_blank">DocEdit Redefined: In-Context Learning for Multimodal Document Editing</a> got accepted at <a href="https://ai4ch.uniud.it/visiondocwacv25/" target="_blank">WACV 2025 workshop</a>  ü•≥!
                    </td>
                </tr>
                <tr>
                    <td>
                        <p style="color:darkblue; display:inline">Sep '24 &nbsp;</p>
                    </td>
                    <td>
                        Ranked <strong><a href="https://drive.google.com/file/d/1sD4vXVy92h6jVFhyikd62igp6lMlHhBz/view?usp=drive_link">45th</a> out of thousand</strong> teams participated in <a href="https://unstop.com/hackathons/amazon-ml-challenge-amazon-1100713/coding-challenge/200089?d=eyJwYWdlIjoxLCJ0ZWFtSWQiOjIyNzkyMzU1LCJhc3NvY2lhdGlvbklkIjo4NDEzMzl9">Amazon ML Challenge 2024</a>. Eligible for PPI for the role of Applied Scientist Intern.
                    </td>
                </tr>
                <tr>
                    <td>
                        <p style="color:darkblue; display:inline">Jun '24 &nbsp;</p>
                    </td>
                    <td>
                        Our paper <a href="https://ihdia.iiit.ac.in/LineTR/" target="_blank">LineTR: Re-Imagining Text-Line Segmentation</a> got accepted at <a href="https://icpr2024.org/" target="_blank">ICPR 2024</a>  ü•≥!
                    </td>
                </tr>
                <tr>
                    <td>
                        <p style="color:darkblue; display:inline">Mar '24 &nbsp;</p>
                    </td>
                    <td>
                        Selected for <a href="https://mbzuai.ac.ae/ugrip/">UGRIP</a> at <a href="https://mbzuai.ac.ae/">MBZUAI</a> with an acceptance rate of 4%.
                    </td>
                </tr>
                <tr>
                    <td>
                        <p style="color:darkblue; display:inline">Dec '23 &nbsp;</p>
                    </td>
                    <td>
                        Selected as Research intern to work in <a href="https://www.cvc.uab.es/">Computer Vision Center</a>, Spain.
                    </td>
                </tr>
                <tr>
                    <td>
                        <p style="color:darkblue; display:inline">Nov '23 &nbsp;</p>
                    </td>
                    <td>
                        Awarded Merit Scholarship for academic excellence in the year 2022-2023.
                    </td>
                </tr>
                
                <tr>
                    <td>
                        <p style="color:darkblue; display:inline">Feb '23 &nbsp;</p>
                    </td>
                    <td>
                        Selected for Summer Research internship at <a href="https://cvit.iiit.ac.in/">CVIT</a> Lab in IIIT Hyderabad.
                    </td>
                </tr>
                <tr>
                    <td>
                        <p style="color:darkblue; display:inline">Jan '23 &nbsp;</p>
                    </td>
                    <td>
                        Special mention award at NIT Trichy &amp; DataNetiix hackathon for our <a href="https://github.com/hwaseem04/Research-digest">Research digest</a> prototype.
                    </td>
                </tr>
                <tr class="news-default-hide" style="display: none;">
                    <td>
                        <p style="color:darkblue; display:inline">Dec '22 &nbsp;</p>
                    </td>
                    <td>
                        Awarded Merit Scholarship for academic excellence in the year 2021-2022.
                    </td>
                </tr>
                <tr class="news-default-hide" style="display: none;">
                    <td>
                        <p style="color:darkblue; display:inline">Nov '22 &nbsp;</p> 
                    </td>
                    <td>
                        Selected as the Student Coordinator for University's <a href="https://timesofindia.indiatimes.com/city/chennai/two-day-annual-technology-festival-invente-22-held/articleshow/96071808.cms">Annual Tech fest</a>.
                    </td>
                </tr> 
                <!-- <tr>
                    <td>
                        <p style="color:darkblue; display:inline">Jun '21 &nbsp</p>
                    </td>
                    <td>
                        Started working as a Software Engineer Intern at the <a href="https://www.sybill.ai/" target="_blank">Sybill.ai</a>.
                    </td>
                </tr>
                

                <!-- <tr class="news-default-hide">
                    <td>
                        <p style="color:darkblue; display:inline">May '21 &nbsp</p>
                    </td>
                    <td>
                        Selected to attend the <a href="https://www.eeml.eu/" target="_blank">Eastern European Machine Learning (EEML) Summer School</a> organized by <a href="https://www.deepmind.com/" target="_blank">DeepMind</a>.
                    </td>
                </tr> -->

                <tr class="news-default-hide" style="display: none;">
                    <td>
                        <p style="color:darkblue; display:inline">Sept '21 &nbsp;</p>
                    </td>
                    <td>
                        Joined Shiv Nadar University Chennai for B.Tech in Artificial Intelligence and Data Science
                    </td>
                </tr>

            </tbody></table>
            <button style="border:0px transparent; background-color: transparent;outline:none;" type="button" class="collapsible" onclick="(() => {toggleNews('table-row')})()" jf-ext-button-ct="see more">
                See more
            </button>
            </div>
            <hr class="soft">

<!-- Education -->

            <button style="border:0px transparent; background-color: transparent;outline:none;" type="button" class="collapsible" data-toggle="collapse" data-target="#content-education" id="education" jf-ext-button-ct="education"><heading>Education</heading></button>
            <div id="content-education" class="collapse in">

            <table border="0" class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto"><tbody>

                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/logo-blue.webp" width="150" class="side-image">
                        </div>
                    </td>
                    <td style="padding:10px;width:75%;vertical-align:top">
                        <!-- <papertitle style="color:gray"><big>Software Development Engineer Intern</big> </papertitle> <papertitle ><big> | Expedia Group</big></papertitle> -->
                        <papertitle><big>Shiv Nadar University, Chennai</big></papertitle>
                        <br>
                        <papertitle style="color:gray"><big>Bachelor of Technology in </big></papertitle><papertitle><big>Artificial Intelligence and Data Science</big></papertitle>
                        <br>
                        September '21 - May '25
                        <br>
                        <br>
                        <strong>Awards:</strong> 2 times Merit Scholarship Awardee
                        <br>
                        <br>
                        <p>
                            Student Societies:
                            </p><ul>
                                <li>Special Invitee | Students Grievance Redressal Committee (SGRC)</li>
                                <li>Student Coordinator | Invente - Annual Technical Fest</li>
                                <li>Technical Member | Chess Club</li>
                            </ul>
                        <p></p>
                    </td>
                </tr>

            </tbody></table>
            </div>
            <hr class="soft">

<!-- Experience -->

            <button style="border:0px transparent; background-color: transparent;outline:none;" type="button" class="collapsible" data-toggle="collapse" data-target="#content-experience" id="experience" jf-ext-button-ct="experience"><heading>Experience</heading></button>
            <div id="content-experience" class="collapse in">

            <table border="0" class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-top: 10px;"><tbody>
                <!-- <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src='images/Microsoft_logo.png' width="155" class="side-image">
                        </div>
                    </td>
                    <td style="padding:10px;width:75%;vertical-align:top">
                        <papertitle style="color:gray"><big>Research Fellow</big> </papertitle> <papertitle ><big> | Microsoft Research Lab India</big></papertitle>
                        <br>
                        Jul '22 - May '24
                        <br>
                        <br>
                        <p>
                            Advisor: Dr Venkat Padmanabhan and Dr Akshay Nambi
                            <br>
                            My work spans across Systems and Networks, ML and Optimization, particularly for Indoor Positioning Systems and AV Call Diagnostics. 
                        </p>
                    </td>
                </tr> -->
                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/mbzuai-logo.png" width="170" class="side-image">
                        </div>
                    </td>
                    <td style="padding:10px;width:75%;vertical-align:top">
                        <papertitle style="color:gray"><big>Visiting Researcher</big> </papertitle> <papertitle><big> | SPriNT-AI Lab </big></papertitle>
                        <br>
                        July '24 - August '24
                        <!-- <br> -->
                        <!-- <br> -->
                        <p>
                            Working in <a href="https://www.sprintai.org/" target="_blank">SPriNT-AI (Security, Privacy and Trustworthiness in Artificial Intelligence) lab</a>, focussing on effective utilization of shapley values in federated learning for non-iid setting.
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/mbzuai-logo.png" width="170" class="side-image">
                        </div>
                    </td>
                    <td style="padding:10px;width:75%;vertical-align:top">
                        <papertitle style="color:gray"><big>UGRIP Intern</big> </papertitle> <papertitle><big> | ViLA Lab</big></papertitle>
                        <br>
                        May '24 - June '24
                        <p><em><a href="https://hwaseem04.github.io/blogs/ugrip/" target="_blank">[My Experience]</a></em></p>
                        <!-- <br> -->
                        <!-- <br> -->
                        <p>
                            Our project, conducted under Dr. Zhiqiang Shen (Jason), focused on "Optimizing Prompts for Foundation Models" to reduce hallucination. We curated a benchmark dataset of 25k questions across ~60 topics like law, philosophy, and history. Additionally, we developed a web application to collect human preferences and assess the correctness of responses before and after applying 26 guiding principles. This preference data is crucial for future preference-based optimization techniques, enhancing the accuracy and reliability of AI-generated responses
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/CVC-logo-color.png" width="120" class="side-image">
                        </div>
                    </td>
                    <td style="padding:10px;width:75%;vertical-align:top">
                        <papertitle style="color:gray"><big>Research Intern</big> </papertitle> <papertitle><big> | Computer Vision Center (CVC)</big></papertitle>
                        <br>
                        Feb '24 - Present
                        <br>
                        <br>
                        <p>
                            Working on document editing. Currently analysing the potential of LLMs to generate structured commands to edit documents.
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/cvit-logo.png" width="120" class="side-image">
                        </div>
                    </td>
                    <td style="padding:10px;width:75%;vertical-align:top">
                        <papertitle style="color:gray"><big>Research Intern</big> </papertitle> <papertitle><big> | Center for Visual Information Technology (CVIT)</big></papertitle>
                        <br>
                        May '23 - Feb '24
                        <br>
                        <br>
                        <p>
                            Co-Developed on a novel method to achieve precise text line segmentation for complex Indic and Southeast Asian historical palm leaves.
                        </p>
                    </td>
                </tr>

            </tbody></table>
            </div>
            <hr class="soft">

<!-- Publications -->

            <button style="border:0px transparent; background-color: transparent;outline:none;" type="button" class="collapsible" data-toggle="collapse" data-target="#content-publications" id="publications" jf-ext-button-ct="publications"><heading>Publications</heading></button>
            <div id="content-publications" class="collapse in">

            <table border="0" class="bg_colour" style="padding:20px;width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/metric-pipeline.png" width="190">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <papertitle><big>DocEdit Redefined: In-Context Learning for Multimodal Document Editing</big></papertitle>
                        <br>
                        <p>
                            <strong>Muhammad Waseem</strong>, Sanket Biswas, Josep Llados
                            <br>
                            <strong>VisionDocs:</strong> Workshop on Computer Vision Systems for Document Analysis and Recognition <strong>WACV 2025</strong>
                            <br>
                            <em><a href="" target="_blank">[paper]</a></em>
                        </p>
                        <p>
                            We introduce an innovative approach to structured document editing that uses Visual-Language Models (VLMs) to simplify the process by removing the need for specialized segmentation tools. Our method incorporates a cutting-edge in-context learning framework to enhance flexibility and efficiency in tasks like spatial alignment, component merging, and regional grouping. By leveraging open-world VLMs, we ensure that document edits preserve coherence and intent. To benchmark our approach, we introduce a new evaluation suite and protocol that assess both spatial and semantic accuracy, demonstrating significant advancements in structured document editing.
                            <!-- Results from our deployments show that HyWay enables effective 
                            mingling. -->
                        </p>
                        <!-- <p><small>*Author order reverse alphabetical
                        </small></p> -->
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/LineTr.png" width="190">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <papertitle><big>LineTR: Unified Text Line Segmentation for Challenging Palm Leaf Manuscripts</big></papertitle>
                        <br>
                        <p>
                            Vaibhav Agrawal, Niharika Vadlamudi, <strong>Muhammad Waseem</strong>, Amal Joseph, Sreenya Chitluri, Ravi Kiran Sarvadevabhatla
                            <br>
                            <strong>ICPR 2024</strong>
                            <br>
                            <em><a href="https://ihdia.iiit.ac.in/LineTR/" target="_blank">[paper]</a></em>
                        </p>
                        <p>
                            We present LineTR, a novel two-stage approach for precise line segmentation in diverse and challenging handwritten historical manuscripts. LineTR's first stage uses a DETR-style network and a hybrid CNN-transformer to process image patches and generate text scribbles and an energy map. A robust, dataset-agnostic post-processing step produces document-level scribbles. In the second stage, these scribbles and the text energy map are used to generate precise polygons around text lines. We introduce three new datasets of Indic and South-East Asian manuscripts and demonstrate LineTR's superior performance and effectiveness in zero-shot inference across various datasets.
                            <!-- Results from our deployments show that HyWay enables effective 
                            mingling. -->
                        </p>
                        <!-- <p><small>*Author order reverse alphabetical
                        </small></p> -->
                    </td>
                </tr>
<!--                     
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src='images/ScienceQA.png' width="150">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <papertitle><big>ScienceQA: A Novel Benchmark Resource for Question Answering on Scholarly Articles</papertitle></big>
                        <br>
                        <p>
                            Tanik Saikh, Tirthankar Ghosal, <strong>Muhammad Waseem</strong>, Asif Ekbal, Pushpak Bhattacharyya
                            <br>
                            International Journal of Digital Libraries (<strong>IJDL</strong>), 2022
                            <br>
                            <em><a href="https://link.springer.com/article/10.1007/s00799-022-00329-y" target="_blank">[paper]</a></em>
                        </p>
                        <p>
                            We introduce a semi-automated dataset having more than 100k 
                            human-annotated context-question-answer triplets to facilitate question answering 
                            (QA) on scientific articles. Secondly, we implement 
                            QA models based on BERT, SciBERT and a combination of
                            SciBERT and BiDAF and evaluate the results on our dataset. The
                            best model obtains an F1 score of 75.46%.
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src='images/ad_text_model.png' width="150">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <papertitle><big>Multi-Modal Detection of Alzheimer's Disease from Speech and Text</papertitle></big>
                        <br>
                        <p>
                            <strong>Amish Mittal*</strong>, Sourav Sahoo*, Arnhav Datar*, Juned Kadiwala*, Hrithwik Shalu, Jimson Mathew
                            <br>
                        20th International Workshop on Data Mining in Bioinformatics (<strong>BIOKDD</strong>) with SIGKDD 2021
                        <br>
                        <em><a href="https://arxiv.org/abs/2012.00096" target="_blank">[paper]</a></em></p>
                        <p>
                            Reliable detection of the prodromal stages of Alzheimer's disease (AD) remains difficult even today because there is no definitive diagnosis of AD in vivo.
                            We propose a multimodal deep learning method that utilizes speech and the corresponding transcript simultaneously to detect AD.
                            <!-- We also perform experiments to analyze the model performance when ASR system generated transcripts are used and further perform an essential study of age and gender bias of our model.  
                            The proposed method achieves 85.3% 10-fold cross-validation accuracy on the Dementiabank Pitt corpus.
                        </p>
                        <p><small>*Authors contributed equally
                            <br>
                            In collaboration with <b> JCBC, University of Cambridge, UK</b>
                        </small></p>
                    </td>
                </tr> -->

            </tbody></table>
            </div>
            <hr class="soft">



<!-- Projects -->

            <button style="border:0px transparent; background-color: transparent;outline:none;" type="button" class="collapsible" data-toggle="collapse" data-target="#content-projects" id="projects" jf-ext-button-ct="key projects"><heading>Key Projects</heading></button>
            <div id="content-projects" class="collapse in">

            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

                <!-- <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src='images/non_monotonic.png' width="150">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <papertitle><big>Making Gradient Descent non-monotonic over gradient (Bachelor Thesis)</papertitle></big>
                        <br>
                        <p>
                            <em><a href="./data/Bachelor_Thesis.pdf" target="_blank">[thesis]</a></em>&nbsp;
                            <em><a href="./data/Bachelor_Thesis_Slides.pdf" target="_blank">[slides]</a></em>&nbsp;
                            <em><a href="https://github.com/fliptrail/non-monotonic-descent" target="_blank">[code]</a></em>
                        </p>
                        <p>
                            Advisor: Prof Jimson Mathew <br>
                            A novel non-monotonic gradient descent optimizer which aims to reduce the number of divergences while using gradient descent, along with its theoretical and empirical validation.
                        </p>
                    </td>
                </tr> -->

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/pca_clients_round_49.png" width="150">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <papertitle><big>FedEmbed</big></papertitle>
                        <br>
                        <p><em><a href="https://github.com/hwaseem04/fedembed/" target="_blank">[code]</a></em> </p>
                        <p>
                            Explored Nearest Neighbor-Based Classification in Federated Learning with Inspiration from Semantic Drift Compensation in Class-Incremental learning to improve model robustness in highly non-IID settings. Achieved promising results in proof-of-concept visualizations.
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/amazon-hack.png" width="150">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <papertitle><big>Multi-modal product details extractor</big></papertitle>
                        <br>
                        <p><em><a href="https://github.com/hwaseem04/Amazon-ML-Challenge-2024" target="_blank">[code]</a></em> <em><a href="https://drive.google.com/file/d/1DJ4Xd8vxGaaxQR-Fp-he9hCbavT2XepJ/view?usp=sharing" target="_blank">[report]</a></em> </p>
                        <p>
                            Utilized Vision-Language Model (VLM) with custom prompt template and an augmentation pipeline to accurately extract product details from images. Built a robust post-processing pipeline to validate extracted data‚Äôs measurement units. Improved the overall F1 score by 17%
                        </p>
                    </td>
                </tr>
                
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/low_loss.png" width="150">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <papertitle><big>Uncovering bias and uncertainty in model using Semi-Supervised VAEs</big></papertitle>
                        <br>
                        <p><em><a href="https://github.com/hwaseem04/Uncovering-Bias-Using-VAE/blob/main/SS-VAE.ipynb" target="_blank">[code]</a></em> <em><a href="https://hwaseem04.github.io/blogs/ssvae/" target="_blank">[blog]</a></em></p>
                        <p>
                        This project aims to investigate and quantify the biases present in face detection models. Identified biases include a preference for white faces over black faces, higher accuracy in detecting male faces compared to female faces, better detection of faces without glasses, and variations in accuracy based on different hair colors. The ultimate goal is to highlight these biases and suggest ways to mitigate them, promoting the development of fairer and more inclusive face detection systems.
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/urdu-seamformer.png" width="150">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <papertitle><big>Urdu SeamFormer</big></papertitle>
                        <br>
                        <p><em><a href="https://github.com/hwaseem04/UrduSeamformer" target="_blank">[code]</a></em> <em><a href="https://drive.google.com/file/d/1x6jDApziX_JqaxXyLXXKkozS0l05tbaZ/view?usp=drive_link" target="_blank">[report]</a></em> </p>
                        <p>
                            Addressed dataset-specific challenges for Urdu text-line segmentation and evaluated pre-trained weights for domain adaptation. Integrated the model into the Indian Government‚Äôs Bhashini API during my internship at IIIT Hyderabad.
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/writerVeriification.png" width="150">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <papertitle><big>Writer independent offline handwriting verification</big></papertitle>
                        <br>
                        <p><em><a href="https://github.com/hwaseem04/Writer-Verification-Challenge-NCVPRIPG" target="_blank">[code]</a></em> <em><a href="https://hwaseem04.github.io/blogs/writer/" target="_blank">[blog]</a></em></p>
                        <p>
                            Developed a model using PyTorch CRAFT and Vision Transformer to determine if two handwritten Hindi images are by the same writer. Achieved an AUC of 0.72 and 10th place in a NCVPRIPG workshop competition.
                        </p>
                    </td>
                </tr>

                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <div class="one">
                            <img src="images/nature-inspired.png" width="150">
                        </div>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:top">
                        <papertitle><big>Nature Inspired Neural Networks</big></papertitle>
                        <br>
                        <p><em><a href="https://github.com/hwaseem04/Nature-inspired-Algorithms" target="_blank">[code]</a></em></p>
                        <p>
                            Optimizing neural network weights using nature-inspired algorithms instead of gradient descent and backpropagation. The algorithms include <strong> Ant Colony Optimization, Particle Swarm Optimization, Genetic Algorithm</strong>.
                        </p>
                    </td>
                </tr>
                

                                
            </tbody></table>
            <p>
                More projects can be found on <a href="https://github.com/hwaseem04/">Github</a>
            </p>
            </div>
            
            <hr class="soft">

        </td>
    </tr>
    <tr>
        <td>
            <p>Last updated: December 31, 2024</p>
            <p>This template is a modification to Jon Barron's <a href="https://jonbarron.info/" target="_blank">website</a>. It has further been modified by <a href="https://rishabkhincha.github.io/" target="_blank">Rishab Khincha</a>. Find the source code to my version <a href="https://github.com/fliptrail/fliptrail.github.io" target="_blank">here</a>. Feel free to clone it for your own use while attributing the original author <a href="https://jonbarron.info/" target="_blank">Jon Barron</a>.</p>
        </td>
    </tr>
    <tr>
        <td>
            <p></p>
        </td>
    </tr>
</tbody></table>



<script async="">
window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());

gtag('config', 'G-8EQTMHM42K');

function toggleNews(val) {
    console.log("Setting news items as: ", val)
    const elementsToHide = document.getElementsByClassName("news-default-hide")
    for (const element of elementsToHide){
        element.style.display = val
    }
}

toggleNews("none")
</script>


<div id="jf-ext-auto-filling-notif-kdy47tyr6" count="0" style="position:fixed!important;top:0!important;right:0!important;background-color:green!important;color:#fff!important;padding:5px!important;z-index:10000!important;font-size:16px!important;line-height:16px!important;display:none!important"> Auto Filling... </div><div id="jf-ext-text-captured-kdy47tyr6" style="position:fixed!important;top:0!important;right:0!important;background-color:green!important;color:#fff!important;padding:5px!important;z-index:10000!important;font-size:16px!important;line-height:16px!important;display:none!important"> Captured </div><div id="jf-ext-career-badge-kdy47tyr6" style="display: none !important;"></div></body></html>

